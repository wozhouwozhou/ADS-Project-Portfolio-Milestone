{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77fc9db2",
   "metadata": {},
   "source": [
    "# IST 718 Final Code\n",
    "Team members: Deyu Li, Chensheng Ma, Zeyang Zhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bd6d052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T21:31:32.421614Z",
     "start_time": "2021-12-06T21:31:22.230187Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the packages needed for this project\n",
    "# create spark and sparkcontext objects\n",
    "# Team members: Deyu Li, Chengshen Ma, Zeyang Zhou\n",
    "from pyspark import sql\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "spark = SparkSession.builder.config('spark.driver.memory','8g').config(\"spark.driver.maxResultSize\", \"8g\").\\\n",
    "                                                                config(\"spark.sql.execution.arrow.enabled\", \"true\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "import pyspark\n",
    "from pyspark.ml import feature, regression, Pipeline, classification, pipeline, evaluation, clustering\n",
    "from pyspark.sql import functions as fn, Row\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8b31c06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T21:31:32.437068Z",
     "start_time": "2021-12-06T21:31:32.426062Z"
    }
   },
   "outputs": [],
   "source": [
    "def _map_to_pandas(rdds):\n",
    "    \"\"\" Needs to be here due to pickling issues \"\"\"\n",
    "    return [pd.DataFrame(list(rdds))]\n",
    "\n",
    "def toPandas(df, n_partitions=None):\n",
    "    \"\"\"\n",
    "    Returns the contents of `df` as a local `pandas.DataFrame` in a speedy fashion. The DataFrame is\n",
    "    repartitioned if `n_partitions` is passed.\n",
    "    :param df:              pyspark.sql.DataFrame\n",
    "    :param n_partitions:    int or None\n",
    "    :return:                pandas.DataFrame\n",
    "    \"\"\"\n",
    "    if n_partitions is not None: df = df.repartition(n_partitions)\n",
    "    df_pand = df.rdd.mapPartitions(_map_to_pandas).collect()\n",
    "    df_pand = pd.concat(df_pand)\n",
    "    df_pand.columns = df.columns\n",
    "    return df_pand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d70acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####If JVM crashed, we can use it to reset the gateway\n",
    "# from py4j.java_gateway import JavaGateway\n",
    "# gateway = JavaGateway()                   # connect to the JVM\n",
    "# random = gateway.jvm.java.util.Random()   # create a java.util.Random instance\n",
    "# number1 = random.nextInt(10)              # call the Random.nextInt method\n",
    "# number2 = random.nextInt(10)\n",
    "# print(number1,number2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf34c606",
   "metadata": {},
   "source": [
    "# Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "162576e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T21:31:42.365712Z",
     "start_time": "2021-12-06T21:31:32.438069Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "#book_example = spark.read.parquet('D:/Desktop/Jupyter Notebook/ist 718/project/optiver-realized-volatility-prediction/book_train.parquet')\n",
    "\n",
    "#book_train = spark.read.option(\"header\",True).csv('D:/Desktop/Jupyter Notebook/ist 718/project/optiver-realized-volatility-prediction/train.csv')\n",
    "#book_train = book_train.select('time_id','stock_id',fn.col('target').cast(\"float\"))\n",
    "#trade_example = spark.read.parquet('D:/Desktop/Jupyter Notebook/ist 718/project/optiver-realized-volatility-prediction/trade_train.parquet')\n",
    "\n",
    "#Load the dataset\n",
    "book_example = spark.read.parquet('C:/Users/visco/Downloads/Optiver_Realized_Volatility_Prediction-main/input/optiver-realized-volatility-prediction/book_train.parquet')\n",
    "\n",
    "book_train = spark.read.option(\"header\",True).csv('C:/Users/visco/Downloads/Optiver_Realized_Volatility_Prediction-main/input/optiver-realized-volatility-prediction/train.csv')\n",
    "\n",
    "trade_example = spark.read.parquet('C:/Users/visco/Downloads/Optiver_Realized_Volatility_Prediction-main/input/optiver-realized-volatility-prediction/trade_train.parquet')\n",
    "book_train = book_train.select('time_id','stock_id',fn.col('target').cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The overview of the order dataset\n",
    "book_example.orderBy('stock_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67506f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The overview of the trade dataset\n",
    "trade_example.orderBy('stock_id','time_id','seconds_in_bucket').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965a4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type\n",
    "book_example.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the stock_id \n",
    "book_example.select(\"stock_id\").distinct().orderBy('stock_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d88af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T21:32:22.332981Z",
     "start_time": "2021-12-06T21:31:42.367729Z"
    }
   },
   "outputs": [],
   "source": [
    "# We have 112 different stocks.\n",
    "stock_count= book_example.select(\"stock_id\").distinct().count()\n",
    "# In one stock, we have 3830 time windows and each of them is limited in a ten minutes scale.\n",
    "time_id_count= book_example.select(\"time_id\").distinct().count()\n",
    "# One time id means an order or trade happened in an unknown 10 minutes scale in the stock market.\n",
    "#plt.scatter(book_example11.select('seconds_in_bucket').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6813b319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T21:32:22.531379Z",
     "start_time": "2021-12-06T21:32:22.333982Z"
    }
   },
   "outputs": [],
   "source": [
    "# Wap 1\n",
    "book_example= book_example.withColumn('wap',(fn.col('bid_price1')*fn.col('ask_size1')+fn.col('ask_price1')*fn.col('bid_size1'))/\\\n",
    "                           (fn.col('bid_size1')+fn.col('ask_size1')))\n",
    "# Wap 2\n",
    "book_example= book_example.withColumn('wap2',(fn.col('bid_price2')*fn.col('ask_size2')+fn.col('ask_price2')*fn.col('bid_size2'))/\\\n",
    "                           (fn.col('bid_size2')+fn.col('ask_size2')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b8a17a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T21:32:22.700166Z",
     "start_time": "2021-12-06T21:32:22.533380Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the log return of each stock by window function\n",
    "from pyspark.sql import Window\n",
    "def log_return(list_stock_prices):\n",
    "    log_return1 = fn.log(fn.col('wap'))\n",
    "    log_return2 = fn.lag(fn.col('log_return1')).over(Window.partitionBy(\"stock_id\").orderBy('seconds_in_bucket'))\n",
    "    list_stock_prices = list_stock_prices.withColumn('log_return1',log_return1) \n",
    "    list_stock_prices = list_stock_prices.withColumn('log_return2',log_return2) \n",
    "    list_stock_prices= list_stock_prices.withColumn('log_return',fn.col('log_return1')-fn.col('log_return2'))    \n",
    "    return list_stock_prices\n",
    "example = log_return(book_example)\n",
    "def log_return_w2(list_stock_prices):\n",
    "    log_return3 = fn.log(fn.col('wap2'))\n",
    "    log_return4 = fn.lag(fn.col('log_return3')).over(Window.partitionBy(\"stock_id\").orderBy('seconds_in_bucket'))\n",
    "    list_stock_prices = list_stock_prices.withColumn('log_return3',log_return3) \n",
    "    list_stock_prices = list_stock_prices.withColumn('log_return4',log_return4) \n",
    "    list_stock_prices= list_stock_prices.withColumn('log_return_w2',fn.col('log_return3')-fn.col('log_return4'))    \n",
    "    return list_stock_prices\n",
    "example = log_return_w2(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6adb276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-112\n",
    "index = list(range(121))\n",
    "example_0_1 = example[example.stock_id.isin(index)]\n",
    "example_0_1 = example_0_1.drop('log_return1','log_return2').orderBy('stock_id','seconds_in_bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ffd76bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:51:28.016465Z",
     "start_time": "2021-12-07T02:51:27.977671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the volatility in past 10 mins \n",
    "example_pt = example_0_1.groupBy('stock_id','time_id').agg(fn.sum(fn.col('log_return')**2).alias('past_target')).orderBy('stock_id','time_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f81cc751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:51:28.360640Z",
     "start_time": "2021-12-07T02:51:28.333633Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract distinct time_id (There are the same time windows in all datasets of 127 stocks)\n",
    "example_0_1.createOrReplaceTempView('book_spark_example')\n",
    "time_id_index= spark.sql('select time_id from book_spark_example').dropDuplicates().\\\n",
    "                       select('time_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ceb3fc",
   "metadata": {},
   "source": [
    "## Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f1754a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:51:48.802085Z",
     "start_time": "2021-12-07T02:51:48.311829Z"
    }
   },
   "outputs": [],
   "source": [
    "# bid&ask spread\n",
    "example_0_1 = example_0_1.withColumn('bidask1',fn.col('bid_price1')*fn.col('ask_price1'))\n",
    "example_0_1 = example_0_1.withColumn('bidask2',fn.col('bid_price2')*fn.col('ask_price2'))\n",
    "example_0_1 = example_0_1.withColumn('bidask3',fn.col('bid_price1')*fn.col('ask_price2'))\n",
    "example_0_1 = example_0_1.withColumn('bidask4',fn.col('bid_price2')*fn.col('ask_price1'))\n",
    "\n",
    "example_0_1 = example_0_1.withColumn('diff1',fn.col('bid_price1')*fn.col('bid_size1')-fn.col('bid_price2')*fn.col('bid_size2'))\n",
    "example_0_1 = example_0_1.withColumn('diff2',fn.col('bid_price1')*fn.col('ask_size1')-fn.col('bid_price2')*fn.col('ask_size2'))\n",
    "example_0_1 = example_0_1.withColumn('diff3',fn.col('ask_price1')*fn.col('ask_size1')-fn.col('ask_price2')*fn.col('ask_size2'))\n",
    "example_0_1 = example_0_1.withColumn('diff4',fn.col('ask_price1')*fn.col('bid_size1')-fn.col('ask_price2')*fn.col('bid_size2'))\n",
    "\n",
    "example_0_1 = example_0_1.withColumn('price_spread',(fn.col('bid_price1')-fn.col('ask_price1'))/(fn.col('bid_price1')+fn.col('ask_price1'))/2)\n",
    "example_0_1 = example_0_1.withColumn('price_spread2',(fn.col('bid_price2')-fn.col('ask_price2'))/(fn.col('bid_price2')+fn.col('ask_price2'))/2)\n",
    "\n",
    "example_0_1 = example_0_1.withColumn('bid_spread',fn.col('bid_price1')-fn.col('bid_price2'))\n",
    "example_0_1 = example_0_1.withColumn('ask_spread',fn.col('ask_price1')-fn.col('ask_size2'))\n",
    "example_0_1 = example_0_1.withColumn('bid_ask_spread',fn.col('bid_spread')-fn.col('ask_spread'))\n",
    "\n",
    "#WAP spread\n",
    "example_0_1 = example_0_1.withColumn('wap3',(fn.col('bid_price1')*fn.col('ask_size2')+fn.col('ask_price1')*fn.col('bid_size2'))/\\\n",
    "                           (fn.col('bid_size1')+fn.col('ask_size1')))\n",
    "example_0_1 = example_0_1.withColumn('wap4',(fn.col('bid_price2')*fn.col('ask_size1')+fn.col('ask_price2')*fn.col('bid_size1'))/\\\n",
    "                           (fn.col('bid_size2')+fn.col('ask_size2')))\n",
    "example_0_1 = example_0_1.withColumn('wap_balance',fn.col('wap')-fn.col('wap2'))\n",
    "example_0_1 = example_0_1.withColumn('wap_balance2',fn.col('wap3')-fn.col('wap4'))\n",
    "\n",
    "#size spread\n",
    "example_0_1 = example_0_1.withColumn('total_volume',fn.col('bid_size1')+fn.col('bid_size2')+fn.col('ask_size1')+fn.col('ask_size2'))\n",
    "example_0_1 = example_0_1.withColumn('volume_imbalance',fn.abs(fn.col('ask_size1')+fn.col('ask_size2')-fn.col('bid_size1')-fn.col('bid_size2')))\n",
    "\n",
    "# features spread\n",
    "example_0_1 = example_0_1.withColumn('wap_balance3',fn.col('wap')-fn.col('wap4'))\n",
    "example_0_1 = example_0_1.withColumn('wap_balance4',fn.col('wap2')-fn.col('wap3'))\n",
    "example_0_1 = example_0_1.withColumn('wap_balance5',fn.col('wap2')-fn.col('wap4'))\n",
    "\n",
    "example_0_1 = example_0_1.withColumn('bidsize_spread',fn.col('bid_size1')-fn.col('ask_size1'))\n",
    "example_0_1 = example_0_1.withColumn('bidsize_spread1',fn.col('bid_size1')-fn.col('ask_size2'))\n",
    "example_0_1 = example_0_1.withColumn('asksize_spread',fn.col('bid_size2')-fn.col('ask_size2'))\n",
    "example_0_1 = example_0_1.withColumn('bidsize_asksize_spread',fn.col('bidsize_spread')-fn.col('asksize_spread'))\n",
    "\n",
    "example_0_1 = example_0_1.withColumn('wap_sqrt1',fn.sqrt('wap'))\n",
    "example_0_1 = example_0_1.withColumn('wap_sqrt2',fn.sqrt('wap2'))\n",
    "example_0_1 = example_0_1.withColumn('wap_sqrt3',fn.sqrt('wap3'))\n",
    "example_0_1 = example_0_1.withColumn('wap_sqrt4',fn.sqrt('wap4'))\n",
    "\n",
    "example_0_1 = example_0_1.withColumn('bid_sqrt1',fn.sqrt('bid_price1'))\n",
    "example_0_1 = example_0_1.withColumn('bid_sqrt2',fn.sqrt('bid_price2'))\n",
    "example_0_1 = example_0_1.withColumn('ask_sqrt1',fn.sqrt('ask_price1'))\n",
    "example_0_1 = example_0_1.withColumn('ask_sqrt2',fn.sqrt('ask_price2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d2be3f",
   "metadata": {},
   "source": [
    "## Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55fa8da4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:52:07.515221Z",
     "start_time": "2021-12-07T02:51:50.508329Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting\n",
    "training_df_index, validation_df_index, testing_df_index = time_id_index.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
    "# Index match\n",
    "training_df_index = [int(row['time_id']) for row in training_df_index.collect()]\n",
    "validation_df_index = [int(row['time_id']) for row in validation_df_index.collect()]\n",
    "testing_df_index = [int(row['time_id']) for row in testing_df_index.collect()]\n",
    "\n",
    "training_df = example_0_1.where(fn.col('time_id').isin(training_df_index))\n",
    "validation_df = example_0_1.where(fn.col('time_id').isin(validation_df_index))\n",
    "testing_df = example_0_1.where(fn.col('time_id').isin(testing_df_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42eab989",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:53:44.042469Z",
     "start_time": "2021-12-07T02:53:43.596846Z"
    }
   },
   "outputs": [],
   "source": [
    "book_train_0 = book_train.select('*').where(\"stock_id==0 or stock_id ==1\")\n",
    "\n",
    "features = ['seconds_in_bucket','bid_price1','ask_price1','bid_price2',\\\n",
    "           'ask_price2','bid_size1','bid_size2','ask_size2','wap','log_return','wap2','log_return_w2',\\\n",
    "            'wap3','wap4','bidask1','bidask2','bidask3','bidask4','diff1','diff2','diff3','diff4',\\\n",
    "           'price_spread','price_spread2','wap_balance','wap_balance2','bid_spread','ask_spread','bid_ask_spread',\\\n",
    "           'total_volume','volume_imbalance','wap_balance3','wap_balance4','wap_balance5',\\\n",
    "           'bidsize_spread','bidsize_spread1','asksize_spread','bidsize_asksize_spread','wap_sqrt1','wap_sqrt2','wap_sqrt3',\\\n",
    "           'wap_sqrt4','bid_sqrt1','bid_sqrt2','ask_sqrt1','ask_sqrt2']\n",
    "\n",
    "expressions = [fn.avg(col).alias(col) for col in features]\n",
    "\n",
    "train_feature= training_df.groupBy('stock_id','time_id').agg(*expressions).orderBy('stock_id','time_id')\n",
    "\n",
    "valid_feature = validation_df.groupBy('stock_id','time_id').agg(*expressions).orderBy('stock_id','time_id')\n",
    "\n",
    "test_feature = testing_df.groupBy('stock_id','time_id').agg(*expressions).orderBy('stock_id','time_id')\n",
    "\n",
    "train_0_1 = train_feature.join(book_train_0, on = ['stock_id','time_id'])\n",
    "valid_0_1 = valid_feature.join(book_train_0, on = ['stock_id','time_id'])\n",
    "test_0_1 = test_feature.join(book_train_0, on = ['stock_id','time_id'])\n",
    "\n",
    "train_0_1 = train_0_1.join(example_pt, on = ['stock_id','time_id'])\n",
    "valid_0_1 = valid_0_1.join(example_pt, on = ['stock_id','time_id'])\n",
    "test_0_1 = test_0_1.join(example_pt, on = ['stock_id','time_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6f4ae3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:54:21.855153Z",
     "start_time": "2021-12-07T02:54:21.814614Z"
    }
   },
   "outputs": [],
   "source": [
    "# We try different combination lists to find the best features\n",
    "feature_list = ['seconds_in_bucket','bid_price1','ask_price1','bid_price2',\\\n",
    "           'ask_price2','bid_size1','bid_size2','ask_size2','wap','log_return','wap2','log_return_w2',\\\n",
    "            'wap3','wap4','bidask1','bidask2','bidask3','bidask4','diff1','diff2','diff3','diff4',\\\n",
    "           'price_spread','price_spread2','wap_balance','wap_balance2','bid_spread','ask_spread','bid_ask_spread',\\\n",
    "           'total_volume','volume_imbalance','wap_balance3','wap_balance4','wap_balance5',\\\n",
    "           'bidsize_spread','bidsize_spread1','asksize_spread','bidsize_asksize_spread','wap_sqrt1','wap_sqrt2','wap_sqrt3',\\\n",
    "           'wap_sqrt4','bid_sqrt1','bid_sqrt2','ask_sqrt1','ask_sqrt2','past_target']\n",
    "\n",
    "kmeans = clustering.KMeans(k=10, featuresCol='features_2', predictionCol='clustering')\n",
    "# Feature pipeline\n",
    "\n",
    "featurize = Pipeline(stages=[\n",
    "    feature.VectorAssembler(inputCols=feature_list,\n",
    "                           outputCol='features_1'),\n",
    "    feature.StandardScaler(withMean=True,\n",
    "                           inputCol='features_1', outputCol='features_2'),\n",
    "    kmeans,\n",
    "    feature.VectorAssembler(inputCols=['clustering','features_2'],\n",
    "                           outputCol='features')\n",
    "]).fit(train_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a899e",
   "metadata": {},
   "source": [
    "## RMSPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b3c8376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:52:07.881506Z",
     "start_time": "2021-12-07T02:52:02.574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rmspe\n",
    "expr = fn.sqrt(fn.mean((((fn.col('target')-fn.col('prediction'))/fn.col('target')))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b1f5ab",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cace36cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T22:21:01.054706Z",
     "start_time": "2021-12-06T22:03:11.672094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48678633325165616\n",
      "0.5740882868901542\n",
      "0.569511666735851\n"
     ]
    }
   ],
   "source": [
    "# Linear model: all features\n",
    "features_df = featurize.transform(train_0_1)\n",
    "features_df = features_df.select('stock_id','time_id','target','features')\n",
    "validation_df_tf=featurize.transform(valid_0_1)\n",
    "validation_df_tf = validation_df_tf.select('stock_id','time_id','target','features')\n",
    "lr_estimator = regression.LinearRegression(featuresCol='features',labelCol='target')\n",
    "lr_estimator = lr_estimator.fit(features_df)\n",
    "prediction_m= lr_estimator.transform(validation_df_tf)\n",
    "predictions_df = prediction_m.select('stock_id','time_id','target','prediction').orderBy('stock_id','time_id')\n",
    "# RMSPE\n",
    "rmspe = predictions_df.select(expr.alias('rmspe'))\n",
    "print(rmspe.toPandas().values[0][0])\n",
    "# R2 and AdjR2\n",
    "print(lr_estimator.summary.r2)\n",
    "print(lr_estimator.summary.r2adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d4bf5",
   "metadata": {},
   "source": [
    "## Stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dab0f456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7704907395797467\n",
      "0.7684489409757145\n",
      "0.5051339281156756\n",
      "0.5044966409441641\n",
      "0.48317289440273675\n",
      "0.5014564715604184\n",
      "0.4992756528522388\n",
      "0.49286218213040867\n",
      "0.49028674511329956\n"
     ]
    }
   ],
   "source": [
    "# We use a for-loop to run our stepwise method\n",
    "feature_list_1 = ['time_id','seconds_in_bucket','bid_price1','ask_price1','bid_price2',\\\n",
    "           'ask_price2','bid_size1','bid_size2','ask_size2','wap','log_return','wap2','log_return_w2',\\\n",
    "            'wap3','wap4','bidask1','bidask2','bidask3','bidask4','diff1','diff2','diff3','diff4',\\\n",
    "           'price_spread','price_spread2','wap_balance','wap_balance2','bid_spread','ask_spread','bid_ask_spread',\\\n",
    "           'total_volume','volume_imbalance','wap_balance3','wap_balance4','wap_balance5',\\\n",
    "           'bidsize_spread','bidsize_spread1','asksize_spread','bidsize_asksize_spread','wap_sqrt1','wap_sqrt2','wap_sqrt3',\\\n",
    "           'wap_sqrt4','bid_sqrt1','bid_sqrt2','ask_sqrt1','ask_sqrt2','past_target']\n",
    "RMSPE = []\n",
    "for i in range(len(feature_list_1)):\n",
    "    feature_list1 = feature_list_1[:i+2]\n",
    "    featurize = Pipeline(stages=[\n",
    "    feature.VectorAssembler(inputCols=feature_list1,\n",
    "                           outputCol='features_1'),\n",
    "    feature.StandardScaler(withMean=True,\n",
    "                           inputCol='features_1', outputCol='features_2'),\n",
    "    kmeans,\n",
    "    feature.VectorAssembler(inputCols=['clustering','features_2'],\n",
    "                           outputCol='features')\n",
    "]).fit(train_0_1)\n",
    "    features_df = featurize.transform(train_0_1)\n",
    "    features_df = features_df.select('stock_id','time_id','target','features')\n",
    "    validation_df_tf=featurize.transform(valid_0_1)\n",
    "    validation_df_tf = validation_df_tf.select('stock_id','time_id','target','features')\n",
    "    lr_estimator = regression.LinearRegression(featuresCol='features',labelCol='target')\n",
    "    lr_estimator = lr_estimator.fit(features_df)\n",
    "    prediction_m= lr_estimator.transform(validation_df_tf)\n",
    "    predictions_df = prediction_m.select('stock_id','time_id','target','prediction').orderBy('stock_id','time_id')\n",
    "    rmspe = predictions_df.select(expr.alias('rmspe'))\n",
    "    rmspe = rmspe.toPandas().values[0][0]\n",
    "    print(rmspe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b9feb2",
   "metadata": {},
   "source": [
    "## GBRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "606a7eb2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-07T01:06:05.761Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
    "## GBTRegressor\n",
    "gbr = GBTRegressor(labelCol='target',seed=0)\n",
    "gbr1 = GBTRegressor(labelCol='target',maxDepth=3, maxBins=20,seed=0)\n",
    "gbr2 = GBTRegressor(labelCol='target',maxDepth=4, maxBins=30,seed=0)\n",
    "gbr3 = GBTRegressor(labelCol='target',maxDepth=5, maxBins=40,seed=0)\n",
    "\n",
    "gbr_pipe = Pipeline(stages=[featurize ,gbr]).fit(train_0_1)\n",
    "gbr_pipe1 = Pipeline(stages=[featurize ,gbr1]).fit(train_0_1)\n",
    "gbr_pipe2 = Pipeline(stages=[featurize ,gbr2]).fit(train_0_1)\n",
    "gbr_pipe3 = Pipeline(stages=[featurize ,gbr3]).fit(train_0_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "154dc57d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T01:06:00.553902Z",
     "start_time": "2021-12-07T01:04:13.813Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction_gbr= gbr_pipe.transform(valid_0_1)\n",
    "predictions_gbr = prediction_gbr.select('stock_id','time_id','target','prediction').orderBy('stock_id','time_id')\n",
    "prediction_gbr1= gbr_pipe1.transform(valid_0_1)\n",
    "predictions_gbr1 = prediction_gbr1.select('stock_id','time_id','target','prediction').orderBy('stock_id','time_id')\n",
    "prediction_gbr2= gbr_pipe2.transform(valid_0_1)\n",
    "predictions_gbr2 = prediction_gbr2.select('stock_id','time_id','target','prediction').orderBy('stock_id','time_id')\n",
    "prediction_gbr3= gbr_pipe3.transform(valid_0_1)\n",
    "predictions_gbr3 = prediction_gbr3.select('stock_id','time_id','target','prediction').orderBy('stock_id','time_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e2511cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T01:06:00.554903Z",
     "start_time": "2021-12-07T01:04:14.501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40711654681934684\n",
      "0.4164272519431899\n",
      "0.405455024684439\n",
      "0.3969574037163013\n"
     ]
    }
   ],
   "source": [
    "rmspe = predictions_gbr.select(expr.alias('rmspe'))\n",
    "rmspe = rmspe.toPandas().values[0][0]\n",
    "print(rmspe)\n",
    "rmspe1 = predictions_gbr1.select(expr.alias('rmspe1'))\n",
    "rmspe1 = rmspe1.toPandas().values[0][0]\n",
    "print(rmspe1)\n",
    "rmspe2 = predictions_gbr2.select(expr.alias('rmspe2'))\n",
    "rmspe2 = rmspe2.toPandas().values[0][0]\n",
    "print(rmspe2)\n",
    "rmspe3 = predictions_gbr3.select(expr.alias('rmspe3'))\n",
    "rmspe3 = rmspe3.toPandas().values[0][0]\n",
    "print(rmspe3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103a3133",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07b443fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T01:06:00.554903Z",
     "start_time": "2021-12-07T01:04:16.369Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "rf1 = RandomForestRegressor(labelCol='target',maxDepth=6, maxBins=60, seed=0)\n",
    "pipe_rf1 = Pipeline(stages=[featurize ,rf1]).fit(train_0_1)\n",
    "rf2 = RandomForestRegressor(labelCol='target',maxDepth=10, maxBins=40, seed=0)\n",
    "pipe_rf2 = Pipeline(stages=[featurize ,rf2]).fit(train_0_1)\n",
    "rf3 = RandomForestRegressor(labelCol='target',maxDepth=30, maxBins=20, seed=0)\n",
    "pipe_rf3 = Pipeline(stages=[featurize ,rf3]).fit(train_0_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cfedfb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T01:06:00.555902Z",
     "start_time": "2021-12-07T01:04:16.768Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction_rf1= pipe_rf1.transform(valid_0_1)\n",
    "predictions_rf1 = prediction_rf1.select('stock_id','time_id','target','prediction').orderBy('stock_id','time_id')\n",
    "prediction_rf2= pipe_rf2.transform(valid_0_1)\n",
    "predictions_rf2 = prediction_rf2.select('stock_id','time_id','target','prediction').orderBy('stock_id','time_id')\n",
    "prediction_rf3= pipe_rf3.transform(valid_0_1)\n",
    "predictions_rf3 = prediction_rf3.select('stock_id','time_id','target','prediction').orderBy('stock_id','time_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69fec4c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T00:06:43.023093Z",
     "start_time": "2021-12-07T00:06:42.768425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressionModel: uid=dtr_b4a328c9dda7, depth=6, numNodes=109, numFeatures=48\n",
      "  If (feature 23 <= -0.19374832230393635)\n",
      "   If (feature 17 <= -1.5381100210787697)\n",
      "    If (feature 13 <= 2.118605676237279)\n",
      "     If (feature 35 <= 0.9328709252406794)\n",
      "      If (feature 38 <= -2.0480748532179027)\n",
      "       Predict: 0.01970827206969261\n",
      "      Else (feature 38 > -2.0480748532179027)\n",
      "       If (feature 42 <= 0.6744653867740833)\n",
      "        Predict: 0.008895230970235282\n",
      "       Else (feature 42 > 0.6744653867740833)\n",
      "        Predict: 0.005359369197062084\n",
      "     Else (feature 35 > 0.9328709252406794)\n",
      "      If (feature 25 <= 0.95957836465277)\n",
      "       If (feature 1 <= -0.4173028031630112)\n",
      "        Predict: 0.011618120595812798\n",
      "       Else (feature 1 > -0.4173028031630112)\n",
      "        Predict: 0.016164269670844077\n",
      "      Else (feature 25 > 0.95957836465277)\n",
      "       If (feature 42 <= 0.47241367678926593)\n",
      "        Predict: 0.007682507392019033\n",
      "       Else (feature 42 > 0.47241367678926593)\n",
      "        Predict: 0.012647481635212898\n",
      "    Else (feature 13 > 2.118605676237279)\n",
      "     Predict: 0.019746173173189163\n",
      "   Else (feature 17 > -1.5381100210787697)\n",
      "    If (feature 47 <= -0.13022649459087182)\n",
      "     If (feature 24 <= -0.7774231317373838)\n",
      "      If (feature 23 <= -3.05475300170095)\n",
      "       If (feature 31 <= -0.13272108586710432)\n",
      "        Predict: 0.015373879704963078\n",
      "       Else (feature 31 > -0.13272108586710432)\n",
      "        Predict: 0.005474243545904756\n",
      "      Else (feature 23 > -3.05475300170095)\n",
      "       If (feature 39 <= -0.019317704103054865)\n",
      "        Predict: 0.007690017817767112\n",
      "       Else (feature 39 > -0.019317704103054865)\n",
      "        Predict: 0.006395915227751898\n",
      "     Else (feature 24 > -0.7774231317373838)\n",
      "      If (feature 47 <= -0.21907925434066547)\n",
      "       If (feature 5 <= -0.5373738226950571)\n",
      "        Predict: 0.003717823829945354\n",
      "       Else (feature 5 > -0.5373738226950571)\n",
      "        Predict: 0.0050968998991828855\n",
      "      Else (feature 47 > -0.21907925434066547)\n",
      "       If (feature 5 <= -0.6332715450829827)\n",
      "        Predict: 0.006969435780774802\n",
      "       Else (feature 5 > -0.6332715450829827)\n",
      "        Predict: 0.00557178158183084\n",
      "    Else (feature 47 > -0.13022649459087182)\n",
      "     If (feature 23 <= -3.05475300170095)\n",
      "      If (feature 27 <= 0.5435491628472038)\n",
      "       If (feature 43 <= -1.2852031449325723)\n",
      "        Predict: 0.008136497810482979\n",
      "       Else (feature 43 > -1.2852031449325723)\n",
      "        Predict: 0.02735411748290062\n",
      "      Else (feature 27 > 0.5435491628472038)\n",
      "       If (feature 47 <= 2.5152101960168425)\n",
      "        Predict: 0.011842529826725904\n",
      "       Else (feature 47 > 2.5152101960168425)\n",
      "        Predict: 0.016748914495110512\n",
      "     Else (feature 23 > -3.05475300170095)\n",
      "      If (feature 1 <= -0.6648704118562241)\n",
      "       If (feature 13 <= -0.3127947033375339)\n",
      "        Predict: 0.006560933058829726\n",
      "       Else (feature 13 > -0.3127947033375339)\n",
      "        Predict: 0.004780039110261461\n",
      "      Else (feature 1 > -0.6648704118562241)\n",
      "       If (feature 33 <= -0.2710343990023081)\n",
      "        Predict: 0.006425543033401482\n",
      "       Else (feature 33 > -0.2710343990023081)\n",
      "        Predict: 0.008546134974687558\n",
      "  Else (feature 23 > -0.19374832230393635)\n",
      "   If (feature 24 <= 0.332369571056107)\n",
      "    If (feature 0 <= 3.5)\n",
      "     If (feature 44 <= -1.301538613225536)\n",
      "      If (feature 36 <= 0.6746910765277045)\n",
      "       If (feature 46 <= -2.054300896660212)\n",
      "        Predict: 0.009172362120201191\n",
      "       Else (feature 46 > -2.054300896660212)\n",
      "        Predict: 0.006257175809393326\n",
      "      Else (feature 36 > 0.6746910765277045)\n",
      "       Predict: 0.012961394153535366\n",
      "     Else (feature 44 > -1.301538613225536)\n",
      "      If (feature 13 <= -0.3127947033375339)\n",
      "       If (feature 27 <= 0.40675690721895097)\n",
      "        Predict: 0.005089789319650403\n",
      "       Else (feature 27 > 0.40675690721895097)\n",
      "        Predict: 0.005983438233407326\n",
      "      Else (feature 13 > -0.3127947033375339)\n",
      "       If (feature 24 <= -0.4086970680112167)\n",
      "        Predict: 0.008282686118036509\n",
      "       Else (feature 24 > -0.4086970680112167)\n",
      "        Predict: 0.0042173602763994214\n",
      "    Else (feature 0 > 3.5)\n",
      "     If (feature 34 <= 0.17316616028112425)\n",
      "      If (feature 23 <= 0.09888032865806928)\n",
      "       If (feature 6 <= 1.094876283733302)\n",
      "        Predict: 0.004013352295509559\n",
      "       Else (feature 6 > 1.094876283733302)\n",
      "        Predict: 0.0025556880049407483\n",
      "      Else (feature 23 > 0.09888032865806928)\n",
      "       If (feature 2 <= -0.18152075181359578)\n",
      "        Predict: 0.00340563183164467\n",
      "       Else (feature 2 > -0.18152075181359578)\n",
      "        Predict: 0.0029338379267995294\n",
      "     Else (feature 34 > 0.17316616028112425)\n",
      "      If (feature 20 <= -0.4522970744210649)\n",
      "       If (feature 16 <= -0.18443258461738665)\n",
      "        Predict: 0.004117513507870691\n",
      "       Else (feature 16 > -0.18443258461738665)\n",
      "        Predict: 0.00297189612349827\n",
      "      Else (feature 20 > -0.4522970744210649)\n",
      "       If (feature 23 <= -0.06252571018558323)\n",
      "        Predict: 0.0055336760058296176\n",
      "       Else (feature 23 > -0.06252571018558323)\n",
      "        Predict: 0.00375461521226254\n",
      "   Else (feature 24 > 0.332369571056107)\n",
      "    If (feature 39 <= -0.5388036543464385)\n",
      "     If (feature 4 <= -0.8274433433407499)\n",
      "      If (feature 24 <= 0.348299864662993)\n",
      "       If (feature 1 <= -0.055788319315363766)\n",
      "        Predict: 0.003936936147511005\n",
      "       Else (feature 1 > -0.055788319315363766)\n",
      "        Predict: 0.007203602511435747\n",
      "      Else (feature 24 > 0.348299864662993)\n",
      "       If (feature 30 <= 0.7881300588602115)\n",
      "        Predict: 0.004768900597133698\n",
      "       Else (feature 30 > 0.7881300588602115)\n",
      "        Predict: 0.0038308264246504557\n",
      "     Else (feature 4 > -0.8274433433407499)\n",
      "      If (feature 40 <= -0.5858951128649352)\n",
      "       If (feature 23 <= 0.656680804218176)\n",
      "        Predict: 0.0034284894171703073\n",
      "       Else (feature 23 > 0.656680804218176)\n",
      "        Predict: 0.0026046512013470583\n",
      "      Else (feature 40 > -0.5858951128649352)\n",
      "       If (feature 7 <= 0.11757042713641658)\n",
      "        Predict: 0.003118216199800372\n",
      "       Else (feature 7 > 0.11757042713641658)\n",
      "        Predict: 0.004837727373731988\n",
      "    Else (feature 39 > -0.5388036543464385)\n",
      "     If (feature 46 <= 0.3247250579377364)\n",
      "      If (feature 43 <= -0.20242356550621815)\n",
      "       If (feature 24 <= 0.6328468562051682)\n",
      "        Predict: 0.0033178980512594855\n",
      "       Else (feature 24 > 0.6328468562051682)\n",
      "        Predict: 0.0025094080981461846\n",
      "      Else (feature 43 > -0.20242356550621815)\n",
      "       If (feature 47 <= -0.2091424886587518)\n",
      "        Predict: 0.0023056613282710398\n",
      "       Else (feature 47 > -0.2091424886587518)\n",
      "        Predict: 0.002754260661828591\n",
      "     Else (feature 46 > 0.3247250579377364)\n",
      "      If (feature 47 <= -0.2238862791952012)\n",
      "       If (feature 6 <= -1.304646490207003)\n",
      "        Predict: 0.004444479088609417\n",
      "       Else (feature 6 > -1.304646490207003)\n",
      "        Predict: 0.0026944549337466375\n",
      "      Else (feature 47 > -0.2238862791952012)\n",
      "       If (feature 31 <= 0.6800940728672589)\n",
      "        Predict: 0.0037144037173880685\n",
      "       Else (feature 31 > 0.6800940728672589)\n",
      "        Predict: 0.0023286155524796675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_tree = pipe_rf1.stages[-1].trees[1].toDebugString\n",
    "print(example_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b990e78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T01:06:00.555902Z",
     "start_time": "2021-12-07T01:04:17.170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4178629738533463\n",
      "0.4070248202754393\n",
      "0.42254949601863223\n"
     ]
    }
   ],
   "source": [
    "rmspe1 = predictions_rf1.select(expr.alias('rmspe'))\n",
    "rmspe1 = rmspe1.toPandas().values[0][0]\n",
    "print(rmspe1)\n",
    "rmspe2 = predictions_rf2.select(expr.alias('rmspe'))\n",
    "rmspe2 = rmspe2.toPandas().values[0][0]\n",
    "print(rmspe2)\n",
    "rmspe3 = predictions_rf3.select(expr.alias('rmspe'))\n",
    "rmspe3 = rmspe3.toPandas().values[0][0]\n",
    "print(rmspe3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
